{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65835f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, json, math, time\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import tmdbsimple as tmdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95751554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'final_tmdb_data_2000.csv.gz',\n",
       " 'title_akas_cleaned.csv.gz',\n",
       " 'title_basics_cleaned.csv.gz',\n",
       " 'title_ratings_cleaned.csv.gz',\n",
       " 'tmdb_api_results_2000.json']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = \"Data/\"\n",
    "os.makedirs(FOLDER, exist_ok=True)\n",
    "os.listdir(FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fe52f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dataframe from project part 1 as basics:\n",
    "basics = pd.read_csv('Data/title_basics_cleaned.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e435d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from learning platfrom.\n",
    "# Credit also: https://www.geeksforgeeks.org/append-to-json-file-using-python/\n",
    "\n",
    "def write_json(new_data, filename): \n",
    "    \"\"\"Appends a list of records (new_data) to a json file (filename). \n",
    "    Adapted from: https://www.geeksforgeeks.org/append-to-json-file-using-python/\"\"\"  \n",
    "    \n",
    "    with open(filename,'r+') as file:\n",
    "        # First we load existing data into a dict.\n",
    "        file_data = json.load(file)\n",
    "        ## Choose extend or append\n",
    "        if (type(new_data) == list) & (type(file_data) == list):\n",
    "            file_data.extend(new_data)\n",
    "        else:\n",
    "             file_data.append(new_data)\n",
    "        # Sets file's current position at offset.\n",
    "        file.seek(0)\n",
    "        # convert back to json.\n",
    "        json.dump(file_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5cde2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS_TO_GET = [2000,2001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "644addd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73298347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start of outer loop\n",
    "#for YEAR in tqdm_notebook(YEARS_TO_GET, desc='YEARS', position=0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82cef447",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c41bcfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the JSON file to store results for year\n",
    "JSON_FILE = f'{FOLDER}tmdb_api_results_{YEAR}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a92acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if file exists\n",
    "file_exists = os.path.isfile(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "257cbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it does not exist: create it\n",
    "if file_exists == False:\n",
    "# save an empty dict with just \"imdb_id\" to the new json file.\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([{'imdb_id':0}],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3b8bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copiedfrom\n",
    "# https://github.com/coding-dojo-data-science/data-enrichment-helper-functions\n",
    "def read_and_fix_json(JSON_FILE):\n",
    "    \"\"\"Attempts to read in json file of records and fixes the final character\n",
    "    to end with a ] if it errors.\n",
    "    \n",
    "    Args:\n",
    "        JSON_FILE (str): filepath of JSON file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: the corrected data from the bad json file\n",
    "    \"\"\"\n",
    "    try: \n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "    \n",
    "    ## If read_json throws an error\n",
    "    except:\n",
    "        \n",
    "        ## manually open the json file\n",
    "        with open(JSON_FILE,'r+') as f:\n",
    "            ## Read in the file as a STRING\n",
    "            bad_json = f.read()\n",
    "            \n",
    "            ## if the final character doesn't match first, select the right bracket\n",
    "            first_char = bad_json[0]\n",
    "            final_brackets = {'[':']', \n",
    "                           \"{\":\"}\"}\n",
    "            ## Select expected final brakcet\n",
    "            final_char = final_brackets[first_char]\n",
    "            \n",
    "            ## if the last character in file doen't match the first char, add it\n",
    "            if bad_json[-1] != final_char:\n",
    "                good_json = bad_json[:-1]\n",
    "                good_json+=final_char\n",
    "            else:\n",
    "                raise Exception('ERROR is not due to mismatched final bracket.')\n",
    "            \n",
    "            ## Rewind to start of file and write new good_json to disk\n",
    "            f.seek(0)\n",
    "            f.write(good_json)\n",
    "           \n",
    "        ## Load the json file again now that its fixed\n",
    "        previous_df =  pd.read_json(JSON_FILE)\n",
    "        \n",
    "    return previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f377248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving new year as the current df\n",
    "df = basics.loc[ basics['startYear']==YEAR].copy()\n",
    "# saving movie ids to list\n",
    "movie_ids = df['tconst'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c5e7a068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9        tt0113026\n",
       "10       tt0113092\n",
       "12       tt0115937\n",
       "13       tt0116391\n",
       "14       tt0116628\n",
       "           ...    \n",
       "82062    tt8327752\n",
       "82823    tt8553964\n",
       "83943    tt8907070\n",
       "84091    tt8954964\n",
       "85576    tt9412476\n",
       "Name: tconst, Length: 1455, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c8b1b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing data from json into a dataframe called \"previous_df\"\n",
    "\n",
    "#previous_df = pd.read_json(JSON_FILE)\n",
    "\n",
    "\n",
    "# For errors...Instead of previous_df=pd.read_json:\n",
    "previous_df = read_and_fix_json(JSON_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a2efccbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb_id\n",
       "0        0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "863621c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any ids that are already in the JSON_FILE\n",
    "movie_ids_to_get = movie_ids[~movie_ids.isin(previous_df['imdb_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "125aae44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbe308604fc42558d67ef698af8a72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies from 2000:   0%|          | 0/1455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    #Get index and movie id from list\n",
    "    # INNER Loop\n",
    "    for movie_id in tqdm_notebook(movie_ids_to_get,\n",
    "                                  desc=f'Movies from {YEAR}',\n",
    "                                  position=1,\n",
    "                                  leave=True):\n",
    "        try:\n",
    "            # Retrieve then data for the movie id\n",
    "            temp = get_movie_with_rating(movie_id)  \n",
    "            # Append/extend results to existing file using a pre-made function\n",
    "            write_json(temp,JSON_FILE)\n",
    "            # Short 20 ms sleep to prevent overwhelming server\n",
    "            time.sleep(0.02)\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors.append([movie_id, e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1df46019",
   "metadata": {},
   "outputs": [],
   "source": [
    "    final_year_df = pd.read_json(JSON_FILE)\n",
    "    final_year_df.to_csv(f\"{FOLDER}final_tmdb_data_{YEAR}.csv.gz\", compression=\"gzip\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "40b7ff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Total errors: 1455\n"
     ]
    }
   ],
   "source": [
    "print(f\"- Total errors: {len(errors)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
